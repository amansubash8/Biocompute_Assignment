{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting FINAL Hybrid Toy data generation...\n"
     ]
    }
   ],
   "source": [
    "import pod5\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.ndimage import gaussian_filter1d \n",
    "import time\n",
    "\n",
    "# --- Settings ---\n",
    "SIGNAL_WINDOW_SIZE = 100 \n",
    "N_SAMPLES = 10000  \n",
    "POD5_FILEPATH = '/Users/aman/Biocompute_assignment/control_rep2.pod5'\n",
    "\n",
    "# --- New File Names ---\n",
    "SAVE_PREFIX = '_adv' \n",
    "\n",
    "all_signal_windows = []\n",
    "all_labels = []\n",
    "\n",
    "print(f\"Starting FINAL Hybrid Toy data generation...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opened /Users/aman/Biocompute_assignment/control_rep2.pod5. Generating 10000 samples...\n",
      "\n",
      "FINAL data generation finished. Total events: 10000\n",
      "Generation took 0.59 seconds.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "np.random.seed(42) \n",
    "half_window = SIGNAL_WINDOW_SIZE // 2\n",
    "signal_count = 0\n",
    "\n",
    "try:\n",
    "    with pod5.Reader(POD5_FILEPATH) as reader:\n",
    "        print(f\"Opened {POD5_FILEPATH}. Generating {N_SAMPLES} samples...\")\n",
    "        \n",
    "        for read in reader.reads():\n",
    "            if signal_count >= N_SAMPLES:\n",
    "                break\n",
    "                \n",
    "            raw_signal = read.signal\n",
    "            if raw_signal.shape[0] < SIGNAL_WINDOW_SIZE:\n",
    "                continue\n",
    "                \n",
    "            # Pick a random spot in the signal to cut out our window\n",
    "            rand_start = np.random.randint(0, raw_signal.shape[0] - SIGNAL_WINDOW_SIZE)\n",
    "            signal_window = raw_signal[rand_start : rand_start + SIGNAL_WINDOW_SIZE].astype(np.float32)\n",
    "            \n",
    "            # Assign a random label (0 or 1)\n",
    "            label = np.random.randint(0, 2)\n",
    "            \n",
    "            # --- PREPROCESSING FIXES ---\n",
    "            # 1. Gaussian Smoothing: [REMOVED]\n",
    "            \n",
    "            if label == 1:\n",
    "                # 2. Add LOUD & RANDOMIZED Spike\n",
    "                \n",
    "                # Randomized Spike Height Multiplier (0.8x to 1.5x)\n",
    "                magnitude_multiplier = np.random.uniform(0.8, 1.5) \n",
    "                \n",
    "                # Randomized Spike Position (Place spike randomly, not just in center)\n",
    "                spike_length = 6\n",
    "                rand_spike_start = np.random.randint(10, SIGNAL_WINDOW_SIZE - spike_length - 10)\n",
    "                \n",
    "                # Define the base spike shape (higher noise than before)\n",
    "                spike = np.array([50, 100, 150, 150, 100, 50])\n",
    "                spike = (spike * magnitude_multiplier) + np.random.normal(0, 40, spike_length)\n",
    "                \n",
    "                # Apply the spike\n",
    "                signal_window[rand_spike_start : rand_spike_start + spike_length] += spike\n",
    "            \n",
    "            # --- NORMALIZATION ---\n",
    "            mean = np.mean(signal_window)\n",
    "            std = np.std(signal_window)\n",
    "            \n",
    "            if std > 0:\n",
    "                normalized_window = (signal_window - mean) / std\n",
    "                all_signal_windows.append(normalized_window)\n",
    "                all_labels.append(label)\n",
    "                signal_count += 1\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n",
    "print(f\"\\nFINAL data generation finished. Total events: {len(all_labels)}\")\n",
    "end_time = time.time()\n",
    "print(f\"Generation took {end_time - start_time:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total X shape: (10000, 100)\n",
      "Total y shape: (10000,)\n",
      "X_train shape: (8000, 100)\n",
      "X_test shape: (2000, 100)\n",
      "\n",
      "All 'advanced' data has been saved to files with prefix '_adv'\n"
     ]
    }
   ],
   "source": [
    "# Convert your lists to big NumPy arrays\n",
    "X = np.array(all_signal_windows)\n",
    "y = np.array(all_labels)\n",
    "\n",
    "print(f\"\\nTotal X shape: {X.shape}\") \n",
    "print(f\"Total y shape: {y.shape}\")\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "\n",
    "# Save these arrays to disk with the new names\n",
    "np.save(f'X_train{SAVE_PREFIX}.npy', X_train)\n",
    "np.save(f'y_train{SAVE_PREFIX}.npy', y_train)\n",
    "np.save(f'X_test{SAVE_PREFIX}.npy', X_test)\n",
    "np.save(f'y_test{SAVE_PREFIX}.npy', y_test)\n",
    "\n",
    "print(f\"\\nAll 'advanced' data has been saved to files with prefix '{SAVE_PREFIX}'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
